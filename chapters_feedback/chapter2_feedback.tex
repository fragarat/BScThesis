\chapter{Continuous-time analysis of dynamical systems}
\label{chap:cont}
When analyzing the importance of \chdeleted{certain} nodes within a network, \chreplaced{it is}{it's} significant to consider the order in which node interactions occur in time. It happens that if person A meets person B today and then person B meets person C tomorrow, a message or idea could pass from A to C, but not the other way around. If we only look at individual moments in time (static snapshots) or a summary of all the interactions, we may miss this type of influence, making it difficult to identify key players in the network. \chreplaced{it is}{It's} reasonable to assume that influential nodes will \chreplaced{introduce}{come up with} information that is then passed around the network by others. Our main motivation is therefore to introduce a framework that can efficiently measure this kind of dynamic effects in a continuous-time setting.

\section{Dynamical system equations}
\label{sec:ode}
Suppose a time-ordered sequence $t_0 < t_1 < \dots < t_M $ and its associated sequence of unweighted graphs defined over a set of $N$ nodes, $\{G^{[k]}\}$ for $k = 0,1,\dots,M$ where each graph records the state of the network at time $t_k$ represented by its corresponding adjacency matrix $A(t_k)$ with $A(t_k)_{ij} = 1$ if exists a link from $i$ to $j$ at time $t_k$ and $0$ otherwise. 
\chcomment{The previous sentence is very long and difficult to read.}
We further assume the existence of directed links, $A(t_k)_{ij} \ne A(t_k)_{ji}$ but no presence of self loops, $A(t_k)_{ii} \equiv 0$. Then, in order to address the previously described follow-on effect derived from the time ordering, the static graph concept of walk is generalized as follows \cite{grindrod2011communicability}:

\chcomment{Is it really necessary that the graph is unweighted?}

\begin{definition}
    A dynamic walk of length $w$ from node $i_1$ to node $i_{w+1}$ consists of a sequence of edges $(i_1,i_2,\dots,i_{w+1})$ and a non-decreasing sequence of times $t_1\le t_2\le \cdots \le t_w$ such that $A(t_m)_{i_m,i_{m+1}}\ne 0$ for $m=1,2,\dots,w$. \chadded{The} Lifetime of a dynamic walk is defined \chdeleted{then} by $t_w - t_1$. 
\end{definition}
Note that more than one edge can share a time slot and that time slots must be ordered to respect the arrow of time but they do not need to be consecutive, i.e. some times may have not been used during the walk.

A key observation that generalizes the static walk mentioned in \chdeleted{Eq.}(\ref{eqn:katz5}) is that the matrix product $\mathbf{A} = A(t_1)A(t_2)\cdots A(t_w)$ has elements $\mathbf{A}_{ij}$ that count the number of dynamic walks of length $w$ from node $i$ to node $j$ on which the $m$'th step of the walk takes place at time $t_m$. In this new dynamic environment, we can utilize the same reasoning that was employed to calculate the Katz centrality metric. Our aim is to measure how likely it is for node $i$ to engage in communication or interactions with node $j$. To achieve this, we can count the number of dynamic walks that go from node $i$ to node $j$ for each length $w$, reducing its significance by multiplying them with a downweighting factor \chdeleted{of} $\alpha^w$. This leads to the matrix product $\alpha^wA(t_1)A(t_2)\cdots A(t_w)$ for $t_1\le t_2\le \cdots \le t_w$ which motivates the definition of \chadded{the} \textit{dynamic communicability matrix}:

\begin{equation}
\label{eqn:dyncommat}
    \mathbf{Q}(t_M) \coloneqq (\mathbf{I} - \alpha\mathbf{A}(t_0))^{-1} (\mathbf{I} - \alpha\mathbf{A}(t_1))^{-1} \cdots (\mathbf{I} - \alpha\mathbf{A}(t_M))^{-1}
\end{equation}
or equivalently expressed by iteration,

\begin{equation}
\label{eqn:dyncommatiter}
    \mathbf{Q}(t_k) = \mathbf{Q}(t_{k-1})(\mathbf{I} - \alpha\mathbf{A}(t_k))^{-1} , ~~~k=0,1,\dots,M
\end{equation}
with $\mathbf{Q}(t_{-1})=I$ \chdeleted[comment={(it's clear from context)}]{of order $N$}.

To assure convergence, as in \chadded{the} static network case, the parameter \chreplaced{$\alpha$}{alpha} is assumed to be between $0<\alpha<1/\rho*$ where $\rho* = \underset{k=0:M}{\max}\{\rho(\mathbf{A}(t_k))\}$ is the largest spectral radius among the spectral radii of the matrices $\{A(t_k)\}$, playing the same role as in classical Katz centrality, i.e. the probability that a message succesfully traverses an edge. In fact, the static Katz centrality is \chdeleted{indeed} a particular case of the previous equation for $k=0$.

The above requirement of $\alpha < 1/\rho*$ ensures that resolvents in Eq. (\ref{eqn:dyncommat}) exist and can be expanded as $(\mathbf{I} - \alpha\mathbf{A}(t_k))^{-1} = \sum_{w=0}^{\infty} (\alpha \mathbf{A}(t_k))^w$. It follows that the entries $\mathbf{Q}(t_k)_{ij}$ represent a weighted sum of the number of dynamic walks from $i$ to $j$ using the ordered sequence of matrices $\{\mathbf{A}(t_0),\mathbf{A}(t_1),\dots,\mathbf{A}(t_k)\}$ penalizing walks of length $w$ by a factor of $\alpha^w$. Hence, $\mathbf{Q}(t_k)_{ij}$ provides an overall measure of the ability of node $i$ to send messages to node $j$ with longer walks having less influence \chreplaced{than shorter ones.}{on such origin node, $i$.}

It is crucial to acknowledge that the use of $\mathbf{Q}(t_k)$ is closely linked to the concept of a starting point $t_0$ and an ending point $t_M$, that is, any walk that occurred within the time frame of $t_0$ to $t_M$ holds the same level of significance.
\chcomment{What does it mean that they have the same significance?}
Additionally, the components in $\mathbf{Q}(t_k)$ are non-negative and increase in value with $k$, ensuring that pairs of nodes do not become less communicative over time. These characteristics are appropriate for certain applications, but many other prioritize current and recent activity, disregarding activity from a distant past, as messages can become outdated, rumors lose relevance, or certain viruses become less contagious. Similar to the concept of the walk-downweighting parameter $\alpha$, Grindrod \& Higham \cite{grindrod2013matrix} considered the use of age-downweighting in the construction of the communicability matrix to further account for the decay of information intensity due to its
aging in time. They realized that at one end of the spectrum, matrix $\mathbf{A}(t_k)$ provides the most localized insight, indicating what is feasible using only today's connectivity and single steps. At the other end of the spectrum, matrix $\mathbf{Q}(t_k)$ provides the most historical view, displaying what is possible using all walks over all connections that have ever existed until the current time. This idea gives rise to a new a matrix iteration that bridges the gap between these two extremes.

So in search of a time-varying "running summary" of communicability between pairs of nodes at each moment in time, our goal is to measure \chadded{the ability of} a node $i$ \chdeleted{ability} to transfer messages to node $j$ considering two \chreplaced{conditions}{parameters}: 
\begin{enumerate}[label=(\roman*)]
  \item \chdeleted{As previously discussed for static networks,} short walks are more relevant than long walks.
  \item Walks that commenced recently are more relevant than those that began a while ago.
\end{enumerate}

 These conditions \chreplaced{motivate}{motivated} the concept of a \textit{running dynamic communicability matrix}, $\mathbf{S}(t)\in\mathbb{R}^{N\times N}$ that generalize the product form in Eq. (\ref{eqn:dyncommat}), such that $\mathbf{S}(t)_{ij}$ quantifies the ability of node $i$ to communicate with node $j$ up to time $t$:
 
\begin{equation}
\label{eqn:rundyncommatdis}
    \mathbf{S}(t_{k+1}) = (\mathbf{I} -  \alpha \mathbf{A}(t_{k+1})^{-\Delta t_{k+1}}\left[\mathbf{I} + e^{-\beta\Delta t_k} (\mathbf{S}(t_k) - \mathbf{I})\right]
\end{equation}

\chcomment{A right paranthesis is missing somewhere.}

 with $\mathbf{S}(t_0) = (\mathbf{I} - \alpha \mathbf{A}(t_0))^{-\Delta t_0}$, $\mathbf{I}\in \mathbb{R}^{N\times N}$ denoting the identity matrix and \chadded{where} $\alpha \in (0,1)$, $\beta > 0$ are two parameters where $\alpha$ is used to downweight walks of length $w$ by the factor $\alpha^w$ and $\beta$ is employed to reduce the weight of the activity, which is age-dependent by the factor $e^{-\beta t}$ if we consider the current age, $t$, of a dynamic walk as the time that has elapsed since the walk began, penalizing past activity that is considered old with respect to $t$.
 \chcomment{Break the previous sentence into shorter, more readable chunks. What is $\Delta t_k$?}
 This factor $e^{-\beta\Delta t_k}$ in \chdeleted{Eq.} (\ref{eqn:rundyncommatdis}) may be interpreted as the probability that a message does not become "irrelevant" over a time length $\Delta t_k$. \chreplaced{It is}{It's} worth mentioning that the iteration in that same equation takes into account the scenario of nonuniform time intervals. By taking $\Delta t_k = 1$ for all $k$ and $\beta = 0$ (no down-scaling in time i.e. infinitely-long memory) the communicability matrix in \chdeleted{Eq.} (\ref{eqn:rundyncommatdis}) recovers the original iteration product form in \chdeleted{Eq.} (\ref{eqn:dyncommat}). On the other hand, for $\Delta t_k = 1$ and $\beta \to \infty$, that is, $e^{-\beta\Delta t_k}\to 0$ (complete downscaling in time or zero memory), the communicability matrix yields $\mathbf{S}(t)=(\mathbf{I} - \alpha \mathbf{A}(t))^{-1}$ degrading to static Katz centrality.

 So far, we have considered an environment where a fixed grid of time points are chosen but our aim, as previously stated, is to develop a new continuous-time framework. On that basis, $\mathbf{S}(t)$ is proposed to be updated over a small time interval $\delta t$. Then, \chdeleted{Eq.} (\ref{eqn:rundyncommatdis}) can be rewritten as
 
 \begin{equation}
\label{eqn:rundyncommat}
    \mathbf{S}(t + \delta t) = (\mathbf{I} + e^{-\beta\delta t}\mathbf{S}(t)) (\mathbf{I} - \alpha\mathbf{A}(t+\delta t))^{-\delta t} - \mathbf{I}
\end{equation} 

with $\mathbf{S}(0)=0$. \chcomment{Explain what simplifications you have used here.}

Conceiving a $\delta t$-dependent power in the matrix products of \chdeleted{Eqs.} (\ref{eqn:rundyncommat} \chreplaced{---}{and} \ref{eqn:rundyncommatdis}) is a fundamental step for the derivation of this new framework. This is explained in the idea of considering a scenario where $\delta t \to 0$. So, over very short periods of time $[t,t+\delta t]$, where downscaling in time is meaningless, i.e. $\beta = 0$, we can always refine to the pair of intervals $[t, t + \delta t/2]$ and $[t + \delta t/2, t + \delta t]$ and assuming $\mathbf{A}(t)$ does not change over this period of time, the following identity 

$$(\mathbf{I} - \alpha\mathbf{A}(t))^{-(1/2)\delta t} (\mathbf{I} - \alpha\mathbf{A}(t))^{-(1/2)\delta t} = (\mathbf{I} - \alpha\mathbf{A}(t))^{-\delta t}$$ show us that this scaling under the limit $\delta t \to 0$ is consistent and meaningful.

From \chdeleted{Eq.} (\ref{eqn:rundyncommat}), taking the identity matrix to the left hand side, we define for convenience $U(t)=I + S(t)$. Then, if we apply the matrix exponential and logarithm with the identities $H =e^{\log H}$ and $\log H^\alpha =\alpha\log H$ for $-1 \le \alpha \le 1$ \cite{higham2008functions} \chdeleted{to that matrix equation}, we obtain 

\chcomment{Bold symbols for matrices in the paragraph above.}

\begin{equation}
\label{eqn:u3.1}
    \mathbf{U}(t + \delta t) = (\mathbf{I} + e^{-\beta\delta t}(\mathbf{U}(t) - \mathbf{I})) \exp\left(-\delta t \log (\mathbf{I} - \alpha \mathbf{A}(t + \delta t)) \right)
\end{equation} 

By taking the limit $\delta t \to 0$,
\chcomment{You have not yet taken the limit.}
expanding in Taylor series to the first order the right-hand
side of \chdeleted{Eq.} (\ref{eqn:u3.1}) and rearranging the terms, this equation can be rewritten as

\begin{equation*}
\label{eqn:u3.1b}
    \frac{\mathbf{U}(t + \delta t) - \mathbf{U}(t)}{\delta t} = -\beta (\mathbf{U}(t) - \mathbf{I}) - \mathbf{U}(t)\log (\mathbf{I} - \alpha \mathbf{A}(t)) + \mathcal{O}(\delta t)
\end{equation*}

Thus, we finally arrive at the matrix ODE proposed by \textsl{Grindrod and Higham}
\chcomment{No reason to italicize.}
\cite{grindrod2014dynamical}, the following non-autonomous Cauchy problem:
\chcomment{Now you have taken the limit!}

\begin{equation}
\label{eqn:u3.3}
    \begin{cases}
      \mathbf{U^{\prime}}(t) = -\beta (\mathbf{U}(t) - \mathbf{I}) - \mathbf{U}(t)\log (\mathbf{I} - \alpha \mathbf{A}(t)), ~~~t>0\\
      \mathbf{U}(0)=\mathbf{I}
    \end{cases}
\end{equation}

This matrix ODE (\ref{eqn:u3.3}) provides us with a continuous-time framework for a dynamic system driven by its adjacency matrix, $\mathbf{A}(t)$ with $\mathbf{U}(t)_{ij}$ for $i\ne j$ quantifying the current ability of node $i$ to pass information to node $j$, so that longer and older walks are less important.

In the same way as we did with Katz centrality for static networks in \chdeleted{Eqs.} (\ref{eqn:broad}\chreplaced{---}{,} \ref{eqn:receiv}), we define two dynamic vectors, namely the broadcast vector $\mathbf{b}(t)$ and the receive vector $\mathbf{r}(t)$, as shown in equation (\ref{eqn:u3.4})\chdeleted{, in order to focus our attention to the individual nodes by summing the rows and columns of the matrix $\mathbf{U}(t)$ respectively}. These vectors enable us to measure the current inclination of each node to broadcast, \chdeleted{$b_i(t)$,} or to receive information, \chdeleted{$r_i(t)$,} across a dynamic network under assumptions of less significance to longer and older walks:

\begin{equation}
\label{eqn:u3.4}
    \mathbf{b}(t) = \mathbf{U}(t)\mathbf{1} \text{~~~and~~~} \mathbf{r}(t) = \mathbf{U}(t)^T\mathbf{1}
\end{equation}

\newpage

\section{Remarks on the new framework}
\label{sec:remarks}

\begin{highlightedParagraphC}
 
Real-time updating of the receive centrality is a factor of $N$ simpler than real-time updating of broadcast centrality.

\end{highlightedParagraphC}

Simulating the dynamic broadcast centrality vector, $\mathbf{b}(t)$, is computationally much more expensive than the dynamic receive vector. $\mathbf{b}(t)$ requires to work with the full matrix $\mathbf{U}(t)$ in Eq. (\ref{eqn:u3.3}) which implies to deal with orders of $\mathcal{O}(N^2)$ for storage and an $\mathcal{O}(N^2)$ cost per unit time. One possible approach to address this problem is to develop approximation techniques, such as sparsifying $\mathbf{U}(t)$ or reducing its dimension.

On the other hand, we note that the receive centrality vector, $\mathbf{r}(t)$, satisfies its own vector-valued ODE, 

\chcomment{Explain how this is derived.}

\begin{equation}
\label{eqn:u4.1}
    \mathbf{r^{\prime}}(t) = -\beta (\mathbf{r}(t) - \mathbf{1}) - (\log (\mathbf{I} - \alpha \mathbf{A}(t)))^T\mathbf{r}(t)
\end{equation} with $\mathbf{r}(0)=\mathbf{1}$, which implies a considerable reduction of order $\mathcal{O}(N)$ with respect to equation (\ref{eqn:u3.3}).

\chcomment{The adjacency matrix is $\mathcal{O}(N^2)$. Does this not impact the cost of \eqref{eqn:u4.1}?}

Unfortunately, it is not possible to derive a vector-valued ODE for the dynamic broadcast vector using the same method. This dissimilarity comes from the fact that the receive vector $\mathbf{r}(t)$ monitors the total amount of information that flows into each node, so this information can be carried forward in time as new links emerge. In contrast, the broadcast vector $\mathbf{b}(t)$ tracks the information that has left each node but it does not indicate the current location of the information because this has not been recorded, and therefore, we cannot update it based solely on $\mathbf{b}(t)$.

\chcomment{Can this be explained mathematically?}

\begin{highlightedParagraphC}
 
The overall dynamic broadcast centrality can be computed via the dynamic receive vector $\mathbf{r}(t)$.

\end{highlightedParagraphC}

The total broadcast centrality of the network, which is represented by $\sum_{i=1}^{N} \mathbf{b}_i(t)$, can be calculated using equation (\ref{eqn:u4.1}).
\chcomment{What is $\mathbf{b}_i(t)$?}
This is because in any matrix, the sum of row sums is equal to the sum of column sums, in our case $\sum_{i=1}^{N} \mathbf{b}_i(t) = \sum_{i=1}^{N} \mathbf{r}_i(t)=\sum_{i=1}^{N}\sum_{j=1}^{N} \mathbf{U}_{ij}(t)$. Therefore, by running a simulation of an ODE system that is $N$ times smaller than the one needed for nodal broadcast information and computing $\mathbf{r}(t)^T\mathbf{1}$, we can keep track of the current broadcast capability of the entire network.

\chcomment{What is the total broadcast centrality used for?}

\newpage

\begin{highlightedParagraphC}
 
 Dynamic vector of receive centralities and aggregate network centrality, may be computed for very large, sparsely connected networks at a reasonable computational cost. 

\end{highlightedParagraphC}

As mentioned above, the aggregate network centrality can be computed via the dynamic receive vector, $\mathbf{r}(t)$, by $$\sum_{i=1}^{N}\sum_{j=1}^{N} \mathbf{U}_{ij}(t) = \sum_{i=1}^{N} \mathbf{r}_i(t)$$

\chcomment{This is the first time you use the phrase 'aggregate network centrality'. This highlight seems to be essentially the same as the previous one, no?}

where the storage requirement for $\mathbf{r}(t)$ scales like the number of nodes in the system, $\mathcal{O}(N)$, and the primary computation involved in evaluating the right-hand side of Eq. (\ref{eqn:u4.1}) can be accomplished by performing only a few products of a sparse matrix with a full vector. This results in a cost of $\mathcal{O}(N)$ per unit time for a network with $\mathcal{O}(1)$ edges per node.

\begin{highlightedParagraphC}
 
The choice of downweighting parameters, $\alpha$ and $\beta$, plays an important role in Eq. \ref{eqn:u3.3} and it is strongly connected to the nature of the interactions represented by $\mathbf{A}(t)$.

\end{highlightedParagraphC}

On one side, the value of the parameter $\beta$, which downweights temporal information, can be interpreted as the rate at which news or information becomes less relevant as time passes. This means that if a piece of information is $t$ units of time old, its relevance will be decreased by $e^{−\beta t}$. Therefore, by studying the typical half-life of a link, we can determine an appropriate value for this parameter and use it to quantify the rate at which information becomes outdated. According to Mason \cite{lifespan}, the lifespan of a link varies greatly depending on its nature. Links belonging to social networks such as YouTube, Facebook or Twitter can remain active between 2-8 hours and, on the contrary, news have a much shorter life with only a few minutes after which they are no longer relevant. To estimate the value of $\beta$, researchers often use statistical methods such as maximum likelihood estimation or least squares regression to fit the decay model to empirical data. This involves finding the value of $\beta$ that best fits the observed decay pattern, based on a set of observed edge weights over time.

On the other hand, the value of the edge-attenuation parameter $\alpha$, which penalizes longer walks in the network, is determined in the discrete case as we saw in (\ref{eqn:dyncommat}) by the reciprocal of the largest spectral radius among the \chdeleted{spectral radii of} the matrices $\{A(t_k)\}$. In a continuous-time ODE system as (\ref{eqn:u3.3}), the logarithm $\log(\mathbf{I} - \alpha \mathbf{A}(t))$ is well-defined if $1 - \alpha \lambda_i > 0$ for all real eigenvalues $\lambda_i$ of $\mathbf{A}(t)$ \cite{higham2008functions}. \chcomment{What about the real part of complex eigenvalues?}

As a particular example, $\alpha$ is constrained by $\alpha < 1$ in the case of one-to-one undirected communication, like voice calls, since the adjacency matrix $A(t)$ \chcomment{(Bold font)} can always be permuted into a block diagonal structure, with non-trivial blocks of the form 

$$\begin{bmatrix}
0 & 1\\
1 & 0 
\end{bmatrix}$$ where $\lambda_1=1$.

\chcomment{I don't understand this last paragraph.}

\begin{highlightedParagraphC}
 
The choice of a distinct starting point in Eq. (\ref{eqn:rundyncommat}), considering other types of dynamic walks, arises a slightly different system of equations.

\end{highlightedParagraphC}

\chcomment{The sentence above is difficult to understand.}

The initial assumption in Eq. (\ref{eqn:rundyncommat}) relies on the concept of counting dynamic walks in a broad sense, encompassing any path that utilizes zero, one, or multiple edges per time step. Alternatively, we could adopt a different approach in which we count other types of dynamic walks by reducing their importance. One possible way to begin this alternative approach is by using the following iteration technique

\begin{equation}
\label{eqn:remarks1}
    \mathbf{S}(t + \delta t) = (\mathbf{I} + e^{-\beta\delta t}\mathbf{S}(t)) (H(\mathbf{A}(t))^{-\delta t} - \mathbf{I}
\end{equation}
where $H(\mathbf{A}(t))$ is some matrix function. One suitable option for this matrix function is to use truncated power series such as $\mathbf{I} + \alpha \mathbf{A}(t) + \alpha^2 \mathbf{A}(t)^2 + \cdots + \alpha^p \mathbf{A}(t)^p$, which only consider dynamic walks that involve a maximum of $p$ edges per time step. When employing this approach, the ODE system (\ref{eqn:u3.3}) takes on a more general form 

\begin{equation}
\label{eqn:remarks2}
    \mathbf{U^{\prime}}(t) = -\beta (\mathbf{U}(t) - \mathbf{I}) + \mathbf{U}(t)\log (H(\mathbf{A}(t)))
\end{equation}

\chcomment{Will you consider such functions in the remainder?}







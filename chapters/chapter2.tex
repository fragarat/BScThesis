\chapter{Continuous-time analysis of dynamical systems}
\label{chap:cont}
When analyzing the importance of nodes within a network, it is significant to consider the order in which node interactions occur in time. It happens that if person A meets person B today and then person B meets person C tomorrow, a message or idea could pass from A to C, but not the other way around. If we only look at individual moments in time (static snapshots) or a summary of all the interactions, we may miss this type of influence, making it difficult to identify key players in the network. It is reasonable to assume that influential nodes will introduce information that is then passed around the network by others. Our main motivation is therefore to introduce a framework that can efficiently measure this kind of dynamic effects in a continuous-time setting.

\section{Dynamical system equations}
\label{sec:ode}
Consider a time-ordered sequence $t_0 < t_1 < \dots < t_M $ and its associated sequence of unweighted graphs defined over a set of $N$ nodes, $\{G^{[k]}\}$ for $k = 0,1,\dots,M$. Each graph reflects the state of the network at time $t_k$ represented by its corresponding adjacency matrix $\mathbf{A}(t_k)$, with $\mathbf{A}(t_k)_{ij} = 1$ if there is a link from $i$ to $j$ at time $t_k$, and $0$ otherwise. We further assume the existence of directed links, $\mathbf{A}(t_k)_{ij} \ne \mathbf{A}(t_k)_{ji}$ but no presence of self loops, $\mathbf{A}(t_k)_{ii} \equiv 0$. We let $\Delta t_i \coloneqq t_i - t_{i-1}$ denote the spacing between successive time points, not assuming that the time points are equally spaced. Then, in order to address the previously described follow-on effect derived from the time ordering, the static graph concept of walk is generalized as follows \cite{grindrod2011communicability}:
\begin{definition}
    A dynamic walk of length $w$ from node $i_1$ to node $i_{w+1}$ consists of a sequence of edges $(i_1,i_2,\dots,i_{w+1})$ and a non-decreasing sequence of times $t_{r_1}\le t_{r_2}\le \cdots \le t_{r_w}$ such that $\mathbf{A}(t_{r_m})_{i_m,i_{m+1}}\ne 0$ for $m=1,2,\dots,w$. The lifetime of a dynamic walk is defined by $t_{r_w} - t_{r_1}$. 
\end{definition}
Note that more than one edge can share a time slot and that time slots must be ordered to respect the arrow of time but they do not need to be consecutive, i.e. some times may have not been used during the walk.

A key observation that generalizes the static walk mentioned in (\ref{eqn:katz3}) is that the matrix product $\mathbf{A} = \mathbf{A}(t_{r_1})\mathbf{A}(t_{r_2})\cdots \mathbf{A}(t_{r_w})$ has elements $\mathbf{A}_{ij}$ that count the number of dynamic walks of length $w$ from node $i$ to node $j$ on which the $m$'th step of the walk takes place at time $t_{r_m}$. In this new dynamic environment, we can utilize the same reasoning that was employed to calculate the Katz centrality metric. Our aim is to measure how likely it is for node $i$ to engage in communication or interactions with node $j$. To achieve this, we can count the number of dynamic walks that go from node $i$ to node $j$ for each length $w$, reducing its significance by multiplying them with a downweighting factor $\alpha^w$. This leads to the matrix product $\alpha^w\mathbf{A}(t_{r_1})\mathbf{A}(t_{r_2})\cdots \mathbf{A}(t_{r_w})$ for $t_{r_1}\le t_{r_2}\le \cdots \le t_{r_w}$ which motivates the definition of the \textit{dynamic communicability matrix}

\begin{equation}
\label{eqn:dyncommat}
    \mathbf{Q}(t_M) \coloneqq (\mathbf{I} - \alpha\mathbf{A}(t_0))^{-1} (\mathbf{I} - \alpha\mathbf{A}(t_1))^{-1} \cdots (\mathbf{I} - \alpha\mathbf{A}(t_M))^{-1},
\end{equation}
or equivalently expressed by iteration,

\begin{equation}
\label{eqn:dyncommatiter}
    \mathbf{Q}(t_k) = \mathbf{Q}(t_{k-1})(\mathbf{I} - \alpha\mathbf{A}(t_k))^{-1} , ~~~k=0,1,\dots,M
\end{equation}
with $\mathbf{Q}(t_{-1})=\mathbf{I}$.

To assure convergence of each resolvent matrix, as in the static network case, the parameter $\alpha$ is assumed to satisfy $0<\alpha<1/\rho^*$ where $\rho^* = \underset{k=0:M}{\max}\{\rho(\mathbf{A}(t_k))\}$ is the largest spectral radius among the spectral radii of the matrices $\{\mathbf{A}(t_k)\}$. Here $\alpha$ plays the same role as in classical Katz centrality, i.e. the probability that a message successfully traverses an edge. In fact, the static Katz centrality is a particular case of \eqref{eqn:dyncommat} for $k=0$.

The requirement of $\alpha < 1/\rho^*$ ensures that resolvents in (\ref{eqn:dyncommat}) exist and can be expanded as $(\mathbf{I} - \alpha\mathbf{A}(t_k))^{-1} = \sum_{w=0}^{\infty} (\alpha \mathbf{A}(t_k))^w$. It follows that the entries $\mathbf{Q}(t_k)_{ij}$ represent a weighted sum of the number of dynamic walks from $i$ to $j$ using the ordered sequence of matrices $\{\mathbf{A}(t_0),\mathbf{A}(t_1),\dots,\mathbf{A}(t_k)\}$ penalizing walks of length $w$ by a factor of $\alpha^w$. Hence, $\mathbf{Q}(t_k)_{ij}$ provides an overall measure of the ability of node $i$ to send messages to node $j$ with longer walks having less influence than shorter ones.

It is important to note that the use of $\mathbf{Q}(t_k)$ is closely linked to the concept of a starting point $t_0$ and an ending point $t_M$, that is, any walk that occurred within the time frame of $t_0$ to $t_M$ holds the same level of influence in terms of time. In other words, all the factors in $\alpha^w\mathbf{A}(t_{0})\mathbf{A}(t_{1})\cdots \mathbf{A}(t_{M})$ have the same consideration of relevance regardless of the time in which they occur. There is no time damping or temporal downweighting of any kind as previously introduced for walk lengths. This feature is appropriate for certain applications, but many other prioritize current and recent activity, disregarding activity from a distant past, as messages can become outdated, rumors lose relevance, or certain viruses become less contagious. 

Similar to the concept of the walk-downweighting parameter $\alpha$, Grindrod \& Higham \cite{grindrod2013matrix} considered the use of age-downweighting in the construction of the communicability matrix to further account for the decay of the relevance of the information. In their study, the researchers adopted a perspective focused on determining whether node $i$ has recently been able to communicate with node $j$ through short walks. They explored two contrasting extremes to capture this information. Firstly, matrix $\mathbf{A}(t_k)$ in \eqref{eqn:dyncommatiter} provides a localized snapshot, revealing the possibilities achievable through single steps based on the current day's connectivity. Conversely, matrix $\mathbf{Q}(t_{k-1})$ offers a historical outlook, encompassing all walks across all past connections leading up to the present time. This idea gives rise to a new a matrix iteration that bridges the gap between these two extremes.

In search of a time-varying "running summary" of communicability between pairs of nodes at each moment in time, our goal is to measure the ability of a node $i$ to transfer messages to node $j$ considering two conditions: 
\begin{enumerate}[label=(\roman*)]
  \item Shorter walks are more relevant than longer walks.
  \item Walks that commenced recently are more relevant than those that began a while ago.
\end{enumerate}

 These conditions motivate the concept of a \textit{running dynamic communicability matrix}, $\mathbf{S}(t)\in\mathbb{R}^{N\times N}$ that generalize (\ref{eqn:dyncommatiter}), such that $\mathbf{S}(t)_{ij}$ quantifies the ability of node $i$ to communicate with node $j$ up to time $t$ \cite{grindrod2013matrix},
 
\begin{equation}
\label{eqn:rundyncommatdis}
    \mathbf{S}(t_{k}) = \left(\mathbf{I} + e^{-\beta\Delta t_k} \mathbf{S}(t_{k-1})\right)\left(\mathbf{I} -  \alpha \mathbf{A}(t_{k})\right)^{-1} - \mathbf{I}, ~~~k=0,1,2,\dots
\end{equation}

 starting for convenience with $\mathbf{S}(t_{-1}) = \mathbf{0}$, where, $\alpha \in (0,1)$ and $\beta > 0$. Here, $\alpha$ is used to downweight walks of length $w$ by the factor $\alpha^w$ and $\beta$ is employed to reduce the weight of the activity, which is age-dependent by the factor $e^{-\beta t}$ if we consider the current age, $t$, of a dynamic walk as the time that has elapsed since the walk began. This factor $e^{-\beta\Delta t_k}$ in (\ref{eqn:rundyncommatdis}) may be interpreted as the probability that a message does not become "irrelevant" over a time length $\Delta t_k$. It is worth mentioning that by taking $\Delta t_k = 1$ for all $k$ and $\beta = 0$ (no down-scaling in time i.e. infinitely-long memory) the communicability matrix in (\ref{eqn:rundyncommatdis}) recovers the original iteration product form in (\ref{eqn:dyncommatiter}) with $\mathbf{S}(t_k) = \mathbf{Q}(t_k) - \mathbf{I}$. On the other hand, for $\Delta t_k = 1$ and $\beta \to \infty$, that is, $e^{-\beta\Delta t_k}\to 0$ (complete downscaling in time or zero memory), the communicability matrix yields $\mathbf{S}(t_k)=(\mathbf{I} - \alpha \mathbf{A}(t_k))^{-1}$ reducing to static Katz centrality.

 So far, we have considered an environment where a fixed grid of time points are chosen but our aim, as previously stated, is to develop a new continuous-time framework. On that basis, $\mathbf{S}(t)$ is proposed to be updated over a small time interval $\delta t$, using the scaling $(\mathbf{I}-\alpha\mathbf{A}(k\delta t))^{-\delta t}$ \cite{grindrod2014dynamical}. Then, (\ref{eqn:rundyncommatdis}) can be rewritten as
 
 \begin{equation}
\label{eqn:rundyncommat}
    \mathbf{S}(t + \delta t) = \left(\mathbf{I} + e^{-\beta\delta t}\mathbf{S}(t)\right) (\mathbf{I} - \alpha\mathbf{A}(t+\delta t))^{-\delta t} - \mathbf{I}
\end{equation} 

with $\mathbf{S}(0)=\mathbf{0}$.
 
To ensure the meaningfulness of the $\delta t\to 0$ limit, a crucial aspect of formulating this new iteration \eqref{eqn:rundyncommat} involved developing such an appropriate scaling approach. The key idea for employing a $\delta t$-dependent power in the matrix products becomes evident when examining the $\beta=0$ case within a short-time interval where downscaling in
time is meaningless. By refining the original single interval $[t,t+\delta t]$ into a pair of intervals $[t, t + \delta t/2]$ and $[t + \delta t/2, t + \delta t]$, and assuming $\mathbf{A}(t)$ remains constant during this interval, we can observe the following straightforward relationship 
 
 $$(\mathbf{I} - \alpha\mathbf{A}(t))^{-\frac{\delta t}{2}} (\mathbf{I} - \alpha\mathbf{A}(t))^{-\frac{\delta t}{2}} = (\mathbf{I} - \alpha\mathbf{A}(t))^{-\delta t}.$$ This identity serves to demonstrate the consistency of our chosen scaling approach, thereby producing reliable and coherent results with \eqref{eqn:dyncommat}.
 
Now, for practical purposes we define the \textit{principal logarithm} of a matrix \cite[Ch.\ 11]{higham2008functions}.
\begin{definition}
    A logarithm of $\mathbf{A} \in \mathbb{C}^{N\times N}$ is any matrix $\mathbf{X}\in \mathbb{C}^{N\times N}$ such that $e^{\mathbf{X}} = \mathbf{A}$ where $e^{\mathbf{X}} = \mathbf{I} + \mathbf{X} + \frac{\mathbf{X}^2}{2!} + \frac{\mathbf{X}^3}{3!} + \cdots$. The matrix logarithm is not unique, since $e^{\mathbf{X}+2k\pi i\mathbf{I}} = \mathbf{A}$ for any integer $k$. If $\mathbf{A}$ has no negative real eigenvalues, then we call this the principal logarithm of $\mathbf{A}$, which is the unique logarithm whose spectrum lies in the strip $\{ z : −\pi < Im(z) < \pi \}$.
\end{definition}
From this point on, we will assume the principal logarithm when referring to the logarithm of a matrix. 

For convenience, we take the identity matrix to the left hand side from (\ref{eqn:rundyncommat}), and define the $\textit{communicability matrix~}$ $\mathbf{U}(t)=\mathbf{I} + \mathbf{S}(t)$. Applying the matrix exponential and matrix logarithm with the identities \cite[Ch.\ 11]{higham2008functions}

$$\mathbf{H} =e^{\log \mathbf{H}} \text{~~and~~} \log \mathbf{H}^\alpha =\alpha\log \mathbf{H} \text{~~~for~~} -1 \le \alpha \le 1,$$ 

we obtain the following identity from \eqref{eqn:rundyncommat}:

\begin{equation}
\label{eqn:u3.1}
    \mathbf{U}(t + \delta t) = \left(\mathbf{I} + e^{-\beta\delta t}(\mathbf{U}(t) - \mathbf{I})\right) \exp\left(-\delta t \log (\mathbf{I} - \alpha \mathbf{A}(t + \delta t)) \right).
\end{equation} 

Expanding in a Taylor series the right-hand side of (\ref{eqn:u3.1}) to the first order 

\begin{align*}
\label{eqn:u3.1b}
    f(\delta t) &= \left(\mathbf{I} + e^{-\beta\delta t}(\mathbf{U}(t) - \mathbf{I})\right) \exp\left(-\delta t \log (\mathbf{I} - \alpha \mathbf{A}(t + \delta t)) \right) \\ 
    f(0) &= \mathbf{U}(t)\\ 
    f'(\delta t) &= - \beta (\mathbf{U}(t) - \mathbf{I})e^{-\beta \delta t}\exp{(-\delta t \log (\mathbf{I}-\alpha \mathbf{A}(t+\delta t)))} +\\ &+ (\mathbf{I} + e^{-\beta \delta t}(\mathbf{U}(t) - \mathbf{I}))(-\log(\mathbf{I}-\alpha \mathbf{A}(t+\delta t)))\exp(-\delta t \log(\mathbf{I}-\alpha \mathbf{A}(t+\delta t)))\\
    f'(0) &= -\beta (\mathbf{U}(t) - \mathbf{I}) - \mathbf{U}(t)\log(\mathbf{I}-\alpha \mathbf{A}(t)),
\end{align*}

and rearranging the terms, \eqref{eqn:u3.1} can be rewritten as

\begin{align*}
\mathbf{U}(t + \delta t) &= \mathbf{U}(t) - \left(\beta (\mathbf{U}(t) - \mathbf{I}) - \mathbf{U}(t)\log(\mathbf{I}-\alpha\mathbf{A}(t))\right) \delta t + \mathcal{O}(\delta t^2) \\
\frac{\mathbf{U}(t + \delta t) - \mathbf{U}(t)}{\delta t} &= -\beta (\mathbf{U}(t) - \mathbf{I}) - \mathbf{U}(t)\log (\mathbf{I} - \alpha \mathbf{A}(t)) + \mathcal{O}(\delta t)
\end{align*}

By taking the limit $\delta t \to 0$, we finally arrive at the matrix ODE proposed by Grindrod and Higham \cite{grindrod2014dynamical}, 

\begin{equation}
\label{eqn:u3.3}
    \begin{cases}
      \mathbf{U^{\prime}}(t) = -\beta (\mathbf{U}(t) - \mathbf{I}) - \mathbf{U}(t)\log (\mathbf{I} - \alpha \mathbf{A}(t)), ~~~t>0\\
      \mathbf{U}(0)=\mathbf{I}.
    \end{cases}
\end{equation}

This matrix ODE (\ref{eqn:u3.3}) provides us with a continuous-time framework for a dynamic system driven by its adjacency matrix, $\mathbf{A}(t)$ with $\mathbf{U}(t)_{ij}$ for $i\ne j$ quantifying the current ability of node $i$ to pass information to node $j$, so that longer and older walks are less important.

In the same way as we did with Katz centrality for static networks in (\ref{eqn:broad}--\ref{eqn:receiv}), we define two dynamic vectors, namely the broadcast vector $\mathbf{b}(t)$ and the receive vector $\mathbf{r}(t)$,

\begin{equation}
\label{eqn:u3.4}
    \mathbf{b}(t) = \mathbf{U}(t)\mathbf{1} \text{~~~and~~~} \mathbf{r}(t) = \mathbf{U}(t)^T\mathbf{1}.
\end{equation}
These vectors enable us to measure, respectively, the current inclination of each node to broadcast or receive information across a dynamic network, under the assumptions of less significance to longer and older walks.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%% REMARKS %%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Remarks on the new framework}
\label{sec:remarks}

\begin{highlightedParagraphC}
 
Real-time updating of the receive centrality is approximately a factor $N$ simpler than real-time updating of broadcast centrality for sparse networks.

\end{highlightedParagraphC}

Simulating the dynamic broadcast centrality vector, $\mathbf{b}(t)$, is computationally much more expensive than the dynamic receive vector. In (\ref{eqn:u3.3}), $\mathbf{b}(t)$ requires to work with the full matrix $\mathbf{U}(t)$ which implies to deal with orders of $\mathcal{O}(N^2)$ for storage and an $\mathcal{O}(N^2)$ cost per unit time. One possible approach to address this problem is to develop approximation techniques, such as sparsifying $\mathbf{U}(t)$ or reducing its dimension.

On the other hand, we note that the receive centrality vector, $\mathbf{r}(t)$, satisfies its own vector-valued ODE. If we transpose both sides of the equality in (\ref{eqn:u3.3}) and multiply on the right by the vector of ones, we obtain

\begin{equation}
\label{eqn:u4.1}
    \mathbf{r^{\prime}}(t) = -\beta (\mathbf{r}(t) - \mathbf{1}) - (\log (\mathbf{I} - \alpha \mathbf{A}(t)))^T\mathbf{r}(t)
\end{equation} with $\mathbf{r}(0)=\mathbf{1}$. This implies a considerable reduction of order $\mathcal{O}(N)$ with respect to equation (\ref{eqn:u3.3}) if we assume that $\mathbf{A}$ represents the adjacency matrix for a sparse network with a computational cost that grows linearly with the number of nonzero entries.

Unfortunately, it is not possible to derive a vector-valued ODE for the dynamic broadcast vector using the same method. This dissimilarity comes from the fact that the receive vector $\mathbf{r}(t)$ monitors the total amount of information that flows into each node, so this information can be carried forward in time as new links emerge. In contrast, the broadcast vector $\mathbf{b}(t)$ tracks the information that has left each node but it does not indicate the current location of the information because this has not been recorded, and therefore, we cannot update it based solely on $\mathbf{b}(t)$. 

\begin{highlightedParagraphC}
 
The total dynamic broadcast centrality and the aggregate network centrality can be computed via the dynamic receive vector $\mathbf{r}(t)$ for large, sparsely connected networks at a reasonable computational cost.

\end{highlightedParagraphC}

The \textit{total broadcast centrality} of the network, which is represented by $\sum_{i=1}^{N} \mathbf{b}(t)_i$, and the \textit{aggregate network centrality}, $\sum_{i=1}^{N}\sum_{j=1}^{N} \mathbf{U}(t)_{ij}$ can be computed using equation (\ref{eqn:u4.1}). This is because in any matrix, the sum of row sums is equal to the sum of column sums. In our case $\sum_{i=1}^{N} \mathbf{b}(t)_i = \sum_{i=1}^{N} \mathbf{r}(t)_i=\sum_{i=1}^{N}\sum_{j=1}^{N} \mathbf{U}(t)_{ij}$. Therefore, by running a simulation of an ODE system that is $N$ times smaller than the one needed for nodal broadcast information, we can keep track of the current broadcast capability of the entire network by computing $\mathbf{r}(t)^T\mathbf{1}$. The storage requirement for $\mathbf{r}(t)$ scales like the number of nodes in the system, $\mathcal{O}(N)$, and the primary computation involved in evaluating the right-hand side of (\ref{eqn:u4.1}) can be accomplished by performing only a few products of a sparse matrix with a full vector. This results in a cost of $\mathcal{O}(N)$ per unit time for a network with $\mathcal{O}(1)$ edges per node.

While total broadcast centrality or aggregate centrality are useful measures for gaining different perspectives on a network at a general level, this study will focus specifically on determining centrality at a node level.

\begin{highlightedParagraphC}
 
The choice of downweighting parameters, $\alpha$ and $\beta$, plays an important role in (\ref{eqn:u3.3}) and it is strongly connected to the nature of the interactions represented by $\mathbf{A}(t)$.

\end{highlightedParagraphC}

On one side, the value of the parameter $\beta$, which downweights temporal information, can be interpreted as the rate at which news or information becomes less relevant as time passes. This means that if a piece of information is $t$ units of time old, its relevance will be decreased by $e^{−\beta t}$. Therefore, by studying the typical half-life of a link, we can determine an appropriate value for this parameter and use it to quantify the rate at which information becomes outdated. According to Mason \cite{lifespan}, the lifespan of a link varies greatly depending on its nature. Links belonging to social networks such as YouTube, Facebook or Twitter can remain active between 2-8 hours and, on the contrary, news have a much shorter life with only a few minutes after which they are no longer relevant. To estimate the value of $\beta$, researchers often use statistical methods such as maximum likelihood estimation or least squares regression to fit the decay model to empirical data. This involves finding the value of $\beta$ that best fits the observed decay pattern, based on a set of observed edge weights over time.

On the other hand, the value of the edge-attenuation parameter $\alpha$, which penalizes longer walks in the network, is determined in the discrete case as we saw in (\ref{eqn:dyncommat}) by the reciprocal of the largest spectral radius among the matrices $\{\mathbf{A}(t_k)\}$. Similarly, for the continuous-time ODE system (\ref{eqn:u3.3}), the principal matrix logarithm function $\log (\mathbf{I} - \alpha \mathbf{A}(t))$ is well-defined when \cite[Ch.\ 11]{higham2008functions} 

$$1 - \alpha\rho(\mathbf{A}(t)) > 0 \iff \alpha < \rho(\mathbf{A}(t))^{-1} \text{~~~for all~~} t>0.$$

This implies that, much like in the discrete case, the full temporal evolution of the network represented by $\mathbf{A}(t)$ has to be known for every $t$ before deriving $\mathbf{U}(t)$.

As a particular example of the choice of $\alpha$, let us consider the context of undirected one-to-one communication, such as voice calls with no teleconferences, i.e., no more than one active connection per node at a given time. It is observed that the the adjacency matrix $\mathbf{A}(t)$ for this kind of network can always be permuted into a block diagonal structure, with non-trivial blocks of the form

$$\begin{bmatrix}
0 & 1\\
1 & 0 
\end{bmatrix}$$ where $\lambda_1=1$.

Consequently, the constraint on $\alpha$ is reduced to $\alpha<1$. This condition will be applied for the choice of the $\alpha$ parameter when dealing with the second and third numerical experiments of this thesis, both of which simulate this type of communication network.

\begin{highlightedParagraphC}

Alternative approaches to resolvent based centrality measures arise by replacing the resolvent function with an opportune matrix function.
 
%The choice of other matrix functions or different types of dynamic walks in the resolvent (\ref{eqn:katz3}), arises a slightly different system of equations.

\end{highlightedParagraphC}

The initial assumption in (\ref{eqn:katz3}) relies on the concept of counting dynamic walks in a broad sense, encompassing any path that utilizes zero, one, or multiple edges per time step. Alternatively, we could adopt a different approach in which we count other types of dynamic walks or matrix functions. One possible way to begin this alternative approach is by using the following iteration technique

\begin{equation}
\label{eqn:remarks1}
    \mathbf{S}(t + \delta t) = (\mathbf{I} + e^{-\beta\delta t}\mathbf{S}(t)) (H(\mathbf{A}(t))^{-\delta t} - \mathbf{I}
\end{equation}
where $H(\mathbf{A}(t))$ is some matrix function. One suitable option for this matrix function is to use truncated power series such as $\mathbf{I} + \alpha \mathbf{A}(t) + \alpha^2 \mathbf{A}(t)^2 + \cdots + \alpha^p \mathbf{A}(t)^p$, which only consider dynamic walks that involve a maximum of $p$ edges per time step. When employing this approach, the ODE system (\ref{eqn:u3.3}) takes on a more general form 

\begin{equation}
\label{eqn:remarks2}
    \mathbf{U^{\prime}}(t) = -\beta (\mathbf{U}(t) - \mathbf{I}) + \mathbf{U}(t)\log (H(\mathbf{A}(t)))
\end{equation}

Truncated power series for the resolvent matrix of the adjacency matrix $\mathbf{A}(t)$ will be used later in this work to approximate the computation of the matrix logarithm in networks involving a large number of nodes.








